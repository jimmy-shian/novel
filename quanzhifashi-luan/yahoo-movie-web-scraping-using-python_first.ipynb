{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 爬蟲實戰範例｜學會抓取 Yahoo奇摩最新電影\n",
    "提供給想學習 Python 爬蟲的朋友們，分享 Python 爬蟲的步驟與方法，並提供完整的程式碼，只要常透過不同主題的實戰練習，就可以駕輕就熟爬蟲技術，往後要抓取網頁資料，就能夠輕易上手\n",
    "\n",
    "網站文章：https://www.webscrapingpro.tw/yahoo-movie-web-scraping-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_txt_title(file,title_all):\n",
    "    filename = file\n",
    "    with open(filename, 'r+', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        f.seek(0, 0)\n",
    "        text = f'{title_all}'\n",
    "        f.write('\\n\\t' + text + '\\n' + content)\n",
    "        \n",
    "def add_html_title(file,title_all):\n",
    "    filename = file\n",
    "    with open(filename, 'r+', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        f.seek(0, 0)\n",
    "        text = f'{title_all}'\n",
    "        f.write(str('<title>') + text + str('</title>'))\n",
    "        f.seek(0, 1)\n",
    "        text = f'{title_all}'\n",
    "        f.write(str('<br>') + str('<center>') + text + str('</center>') + str('<br>') + content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch(soup_url, a):\n",
    "    title = str(soup_url.find('div', 'title'))\n",
    "    # title_name = str(soup_url.find('div', 'prev_page'))\n",
    "    title_name = str('《全職法師》▷ ')\n",
    "    info_items = soup_url.find_all('p')\n",
    "    txt_list = []\n",
    "    html_list = []\n",
    "\n",
    "    title = re.sub(r'<.*?>',\"\",title)\n",
    "    title_name = re.sub(r'<.*?>', \" \", re.sub(r'\\W\\w*章', \" \", title_name))\n",
    "    title_all = title_name + title\n",
    "    # title_name = re.sub(r'<.*?>', \"\", title_name) # title_name = re.sub(r'\\B\\D\\W\\w*章', \"\", title_name)\n",
    "    # print(title_all)\n",
    "\n",
    "    for item in info_items:\n",
    "\n",
    "        txt_item = item.text.strip()\n",
    "        html = str('<br>') + str('&emsp;&emsp;') + str(txt_item) + str('<br>')\n",
    "        use = []\n",
    "        if len(txt_item)+2>40:\n",
    "            k = 0\n",
    "            for i in range(0, int(len(txt_item)/40)+1):\n",
    "                use = txt_item[k:(i+1)*40]\n",
    "                k = k + 40\n",
    "                if i == 0:\n",
    "                    txt_list.append(f'\\n    {use}')\n",
    "                else:\n",
    "                    txt_list.append(f'\\n{use}')\n",
    "        else:\n",
    "            txt_list.append(f'\\n    {txt_item}')\n",
    "            \n",
    "        html_list.append(f'{html}')\n",
    "\n",
    "\n",
    "    np.savetxt('帝霸' + str(a) + '.txt', txt_list, fmt='%s', delimiter=',', encoding='UTF-8')\n",
    "    np.savetxt('帝霸_html' + str(a) + '.html', html_list, fmt='%s', delimiter=',', encoding='UTF-8')\n",
    "\n",
    "    add_txt_title('帝霸' + str(a) + '.txt',title_all)\n",
    "    add_html_title('帝霸_html' + str(a) + '.html',title_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bg3.co/novel/pagea/diba-yanbixiaosheng_100.html\n",
      "https://www.bg3.co/novel/pagea/diba-yanbixiaosheng_200.html\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlxml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m catch(soup, a)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for a in range(14,5352):\n",
    "    url = 'https://www.bg3.co/novel/pagea/diba-yanbixiaosheng_' + str(a) + '.html'\n",
    "    if a%100 == 0:\n",
    "        print(url)\n",
    "    response = requests.get(url=url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    catch(soup, a)\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整的程式碼如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# url = 'https://movies.yahoo.com.tw/movie_thisweek.html'\n",
    "# response = requests.get(url=url)\n",
    "\n",
    "# soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "# info_items = soup.find_all('div', 'release_info')\n",
    "\n",
    "# with open('本週新片.csv', 'w', encoding='utf-8-sig', newline='') as csv_file:\n",
    "    \n",
    "#     csv_writer = csv.writer(csv_file)\n",
    "#     fieldnames = ['電影片名', '電影英文片名', '上映時間', '網友期待度']\n",
    "#     csv_writer.writerow(fieldnames)\n",
    "\n",
    "#     for item in info_items:\n",
    "\n",
    "#         name = item.find('div', 'release_movie_name').a.text.strip()\n",
    "#         english_name = item.find('div', 'en').a.text.strip()\n",
    "#         release_time = item.find('div', 'release_movie_time').text.split('：')[-1].strip()\n",
    "#         level = item.find('div', 'leveltext').span.text.strip()\n",
    "        \n",
    "#         csv_writer.writerow([name, english_name, release_time, level])\n",
    "#         print('{}({}) 上映日：{} 期待度：{}'.format(name, english_name, release_time, level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f51678d26300acc1504d5f231aa64fefd00fb6340e5aa8a951d06e8266bb69e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
